ts_err <- rep(100, length(ntree))
for (i in 1:length(ntree)) {
rf <- randomForest(price~suburb+result+nbeds+property_type+
month+year+nvisits+rating+ncars+nbaths+land_size+house_size,
data=train_sub, ntree=ntree[i])
tr_err[i] <- rf$mse[i]
pred <- predict(rf, test_sub)
ts_err[i] <- MSE(test_sub$price, pred)
}
df <- data.frame(ntree, tr_err, ts_err) %>% gather(type, error, -ntree)
ggplot(df, aes(x=ntree, y=error, colour=type)) +
geom_point() + geom_smooth(se=FALSE) +
ylim(c(0, 0.35)) + scale_colour_brewer(palette="Dark2")
ggplot(df, aes(x=ntree, y=error, colour=type)) +
geom_point() + geom_smooth(se=FALSE)
ggplot(df, aes(x=ntree, y=error, colour=type)) +
geom_point() + geom_smooth(se=FALSE) +
scale_colour_brewer(palette="Dark2")
109+65+22+3+1
65+44+9+4
0.01*0.6+0.001*0.4
0.01*0.6/0.0064
?glm
p <- seq(0, 0.5, 0.1)
l <- 0.6*p-0.2
df <- data.frame(p, l)
ggplot(df, aes(p, l)) + geom_point()
ggplot(df, aes(p, l)) + geom_line()
ggplot(df, aes(p, l)) + geom_line() + ylab("loss")
df <- data.frame(ntree, tr_err, ts_err) %>% gather(type, error, -ntree)
ggplot(df, aes(x=ntree, y=error, colour=type)) +
geom_point(aes(shape=type)) + geom_smooth(aes(linetype=type), se=FALSE) +
scale_colour_brewer(palette="Dark2")
ggplot(df, aes(x=ntree, y=error, colour=type)) +
geom_point(aes(shape=type)) + geom_smooth(aes(linetype=type), se=FALSE) +
scale_colour_brewer("error", palette="Dark2")
ggplot(df, aes(x=ntree, y=error, colour=type)) +
geom_point(aes(shape=type)) + geom_smooth(aes(linetype=type), se=FALSE) +
scale_colour_brewer("error", palette="Dark2") +
scale_linetype("error")
ggplot(df, aes(x=ntree, y=error, colour=type)) +
geom_point(aes(shape=type)) + geom_smooth(aes(linetype=type), se=FALSE) +
scale_colour_brewer("error", palette="Dark2") +
scale_shape("error")
ggplot(df, aes(x=ntree, y=error, colour=type)) +
geom_point(aes(shape=type)) + geom_smooth(aes(linetype=type), se=FALSE) +
scale_colour_brewer("error", palette="Dark2") +
scale_shape("error") +
scale_linetype("error")
ggplot(df, aes(x=ntree, y=error, colour=type)) +
geom_point(aes(shape=type)) + geom_smooth(aes(linetype=type), se=FALSE) +
scale_colour_brewer("error", palette="Dark2") +
scale_shape("error") +
scale_linetype("error") + theme(legend.position="bottom")
ggplot(df, aes(x=ntree, y=error, colour=type)) +
geom_point(aes(shape=type)) + geom_smooth(aes(linetype=type), se=FALSE) +
scale_colour_brewer("error", palette="Dark2") +
scale_shape("error") +
scale_linetype("error") + theme(legend.position="bottom", legend.key.width = 3)
?legend.key.width
?theme
ggplot(df, aes(x=ntree, y=error, colour=type)) +
geom_point(aes(shape=type)) + geom_smooth(aes(linetype=type), se=FALSE) +
scale_colour_brewer("error", palette="Dark2") +
scale_shape("error") +
scale_linetype("error") + theme(legend.position="bottom", legend.key.size = 3)
ggplot(df, aes(x=ntree, y=error, colour=type)) +
geom_point(aes(shape=type)) + geom_smooth(aes(linetype=type), se=FALSE) +
scale_colour_brewer("error", palette="Dark2") +
scale_shape("error") +
scale_linetype("error") + theme(legend.position="bottom", legend.key.size = unit(2, "cm"))
ggplot(df, aes(x=ntree, y=error, colour=type)) +
geom_point(aes(shape=type)) + geom_smooth(aes(linetype=type), se=FALSE) +
scale_colour_brewer("error", palette="Dark2") +
scale_shape("error") +
scale_linetype("error") + theme(legend.position="bottom", legend.key.width = unit(2, "cm"))
library(DArq)
help(package="DArq")
library(quantreg);
library(DArq);
## single censoring case
Z1=rnorm(200);
Z2=rnorm(200);
varep=rt(200,3);
delta=rep(0,200);
y=2*Z1+2*Z2+varep;
Lc=as.numeric(quantile(y, 0.3)); # the left censoring bound
delta[y<=Lc]=1;
y[y<=Lc]=Lc;
L=numeric(200);
U=numeric(200)+1;
L[delta==1]=-Inf; U[delta==1]=Lc;
dat=data.frame(y, Z1, Z2, L, U, delta);
names(dat)=c("y", "Z1", "Z2", "L", "U", "delta");
y=dat$y;
x=as.matrix(dat[,!names(dat) %in% c("y","delta","L","U")]);
L=dat$L;
U=dat$U;
delta=dat$delta;
res.DArq.single=DArq(y, x, delta, L, U, taus=c(0.1, 0.3, 0.5, 0.7, 0.9),iter=50);
## double censoring case
Z1=runif(200);
Z2=runif(200,1,3);
varep=rnorm(200);
delta=rep(0,200);
y=1+6*Z1+3*Z2+(Z1+0.5*Z2)*varep;
Lc=as.numeric(quantile(y, 0.2)); # the left censoring time
Rc=as.numeric(quantile(y, 0.9)); # the right censoring time
delta[y<=Lc]=1;
delta[y>=Rc]=2;
y[y<=Lc]=Lc;
y[y>=Rc]=Rc;
L=numeric(200);
U=numeric(200)+1;
L[delta==1]=-Inf; U[delta==1]=Lc;
L[delta==2]=Rc; U[delta==2]=Inf;
dat=data.frame(y, Z1, Z2, L, U, delta);
names(dat)=c("y", "Z1", "Z2", "L", "U", "delta");
y=dat$y;
x=as.matrix(dat[,!names(dat) %in% c("y","delta","L","U")]);
L=dat$L;
U=dat$U;
delta=dat$delta;
res.DArq.double=DArq(y, x, delta, L, U, taus=c(0.1, 0.3, 0.5, 0.7, 0.9), iter=100, tol=0.01);
res.DArq.double
?gbm
library("tidyverse")
library("forcats")
load("pisa_au.rda")
pisa_au <- pisa_au %>%
mutate(science = (PV1SCIE+PV2SCIE+PV3SCIE+PV4SCIE+
PV5SCIE+PV6SCIE+PV7SCIE+PV8SCIE+
PV9SCIE+PV10SCIE)/10)
pisa_au <- pisa_au %>%
select(science, ST004D01T, OUTHOURS, ANXTEST, EMOSUPP, PARED, JOYSCIE, WEALTH, ST013Q01TA, ST012Q01TA, SENWT)
pisa_au <- pisa_au %>%
select(science, ST004D01T, OUTHOURS, ANXTEST, EMOSUPP, PARED, JOYSCIE, WEALTH, ST013Q01TA, ST012Q01TA, SENWT)
pisa_au <- pisa_au %>% select(-EMOSUPP, -OUTHOURS)
aus_nomiss <- pisa_au %>% #filter(!is.na(OUTHOURS)) %>%
filter(!is.na(ANXTEST)) %>% filter(!is.na(PARED)) %>%
filter(!is.na(JOYSCIE)) %>% filter(!is.na(WEALTH)) %>%
filter(!is.na(ST013Q01TA)) %>% filter(!is.na(ST012Q01TA))
aus_nomiss <- aus_nomiss %>%
mutate(ST004D01T=factor(ST004D01T, levels=c(1,2), labels=c("f", "m")))
ggplot(aus_nomiss, aes(x=JOYSCIE, y=science, colour=ST004D01T)) +
geom_smooth(method="lm") +
scale_colour_brewer(palette="Dark2")
ggplot(aus_nomiss, aes(x=JOYSCIE, y=science,
colour=ST004D01T, linetype=ST004D01T)) +
geom_smooth(method="lm") +
scale_colour_brewer(palette="Dark2")
aus_glm <- glm(science~ST004D01T*JOYSCIE+ST004D01T*ANXTEST+
PARED+WEALTH+ST013Q01TA+ST012Q01TA,
data=aus_nomiss, weights=SENWT)
summary(aus_glm)$coefficients
library(xtable)
xtable(summary(aus_glm)$coefficients)
summary(aus_glm)
aus_glm2 <- glm(science~ST004D01T+JOYSCIE+ANXTEST+
PARED+WEALTH+ST013Q01TA+ST012Q01TA,
data=aus_nomiss, weights=SENWT)
summary(aus_glm2)
29170010-29085855
library(broom)
aus_glm_augment <- augment(aus_glm)
ggplot(aus_glm_augment, aes(x=.hat, y=.cooksd)) + geom_point()
p1 <- ggplot(aus_glm_augment, aes(x=.resid)) + geom_histogram()
n <- nrow(aus_nomiss)
aus_glm_augment$q = qnorm(c(1 - 0.5^(1/n), (2:(n-1) - 0.3175) /
(n + 0.365),0.5^(1/n)), 2, 0.5)
p2 <- ggplot(aus_glm_augment, aes(x=sort(.resid), y=q)) + geom_point() +
geom_smooth(method="lm", se=FALSE) + theme(aspect.ratio=1)
library(gridExtra)
grid.arrange(p1, p2, ncol=2)
p1 <- ggplot(aus_glm_augment, aes(x=.resid)) + geom_histogram()
n <- nrow(aus_nomiss)
aus_glm_augment$q = qnorm(c(1 - 0.5^(1/n), (2:(n-1) - 0.3175) /
(n + 0.365),0.5^(1/n)), 2, 0.5)
p2 <- ggplot(aus_glm_augment, aes(x=sort(.resid), y=q)) + geom_point() +
geom_smooth(method="lm", se=FALSE) + theme(aspect.ratio=1) +
xlab("sample quantiles") + ylab("theoretical quantiles")
library(gridExtra)
grid.arrange(p1, p2, ncol=2)
p1 <- ggplot(aus_glm_augment, aes(x=.resid)) + geom_histogram()
n <- nrow(aus_nomiss)
aus_glm_augment$q = qnorm(c(1 - 0.5^(1/n), (2:(n-1) - 0.3175) /
(n + 0.365),0.5^(1/n)), 2, 0.5)
p2 <- ggplot(aus_glm_augment, aes(x=sort(.resid), y=q)) + geom_point(alpha=0.5) +
geom_smooth(method="lm", se=FALSE) + theme(aspect.ratio=1) +
xlab("sample quantiles") + ylab("theoretical quantiles")
library(gridExtra)
grid.arrange(p1, p2, ncol=2)
p1 <- ggplot(aus_glm_augment, aes(x=.resid)) + geom_histogram()
n <- nrow(aus_nomiss)
aus_glm_augment$q = qnorm(c(1 - 0.5^(1/n), (2:(n-1) - 0.3175) /
(n + 0.365),0.5^(1/n)), 2, 0.5)
p2 <- ggplot(aus_glm_augment, aes(x=sort(.resid), y=q)) +
geom_smooth(method="lm", se=FALSE) + theme(aspect.ratio=1) +
geom_point(alpha=0.2) +
xlab("sample quantiles") + ylab("theoretical quantiles")
library(gridExtra)
grid.arrange(p1, p2, ncol=2)
p1 <- ggplot(aus_glm_augment, aes(x=.resid)) + geom_histogram()
n <- nrow(aus_nomiss)
aus_glm_augment$q = qnorm(c(1 - 0.5^(1/n), (2:(n-1) - 0.3175) /
(n + 0.365),0.5^(1/n)), 2, 0.5)
p2 <- ggplot(aus_glm_augment, aes(x=sort(.resid), y=q)) +
geom_smooth(method="lm", se=FALSE) + theme(aspect.ratio=1) +
geom_point(alpha=0.02) +
xlab("sample quantiles") + ylab("theoretical quantiles")
library(gridExtra)
grid.arrange(p1, p2, ncol=2)
p1 <- ggplot(aus_glm_augment, aes(x=.resid)) + geom_histogram()
n <- nrow(aus_nomiss)
aus_glm_augment$q = qnorm(c(1 - 0.5^(1/n), (2:(n-1) - 0.3175) /
(n + 0.365),0.5^(1/n)), 2, 0.5)
p2 <- ggplot(aus_glm_augment, aes(x=sort(.resid), y=q)) +
geom_smooth(method="lm", se=FALSE) + theme(aspect.ratio=1) +
geom_point(alpha=0.05) +
xlab("sample quantiles") + ylab("theoretical quantiles")
library(gridExtra)
grid.arrange(p1, p2, ncol=2)
6+4+12+12+12+9+21+8+5
6+4+12+12+16+9+21+8+6
6+4+12+15+16+9+21+8+6
6+4+15+15+16+9+21+8+6
0.02*0.70+0.001*0.30
1/20*5/50
1/30*5/50
1/30*4/50
1/40*5/50
1/40*4/50
1/20/(5/50)
1/20/(1/10)
1/30*10
1/30*(25/2)
1/40*10
1/40*(25/2)
1/40*(50/3)
sum(c(rep(5/50, 4), rep(4/50, 2), rep(3/50, 2),
rep(2/50, 4), rep(1/50, 8)))
1/60*10
1/60*(25/2)
1/60*(50/3)
1/60*(20)
1/100*10
1/100*(25/2)
1/100*(50/3)
1/100*(25)
1/100*(50)
c(rep(8/90, 4), rep(7/90, 2), rep(6/90, 2),
rep(5/90, 4), rep(4/90, 8))
sum(c(rep(8/90, 4), rep(7/90, 2), rep(6/90, 2),
rep(5/90, 4), rep(4/90, 8)))
1:20+1:20+1:20+1:12+1:8+1:6+1:4
20+20+20+12+8+6+4
c(rep(7/90, 4), rep(6/90, 2), rep(5/90, 2),
rep(4/90, 4), rep(3/90, 8))
sum(c(rep(7/90, 4), rep(6/90, 2), rep(5/90, 2),
rep(4/90, 4), rep(3/90, 8)))
prior <- c(rep(1/7, 4), 3/7)
prob_D <- c(rep(7/90, 4), rep(6/90, 2), rep(5/90, 2),
rep(4/90, 4), rep(3/90, 8))
dice_posterior <- function(x, dice, prior, prob_D) {
post <- NULL
pD <- prod(prob_D[x])
for (i in 1:length(dice)) {
post <- c(post, prior[i]*dice_likelihood(x, dice[i])/pD)
}
df <- data.frame(dice, post=post/sum(post))
return(df)
}
dice_posterior(6, dice, prior, prob_D)
dice <- c(4, 6, 8, 12, 20)
dice_posterior(6, dice, prior, prob_D)
dice_likelihood <- function(x, dice) {
if (x>dice)
l <- 0
else
l <- 1/dice
return(l)
}
dice_posterior(6, dice, prior, prob_D)
loco_likelihood <- function(x, loco){
if (x>loco)
l <- 0
else
l <- 1/loco
}
l <- NULL
for (i in 1:1000)
l <- c(l, loco_likelihood(60, i))
df <- data.frame(hyp=1:1000, l, post=l/sum(l))
alpha=0.9
prior <- (1/1:1000)^alpha
df <- data.frame(hyp=1:1000, l, unif=l/sum(l))
df$power <- l*prior
df$power <- df$power/sum(df$power)
prior2 <- exp(-(1:1000/3)^2)/sqrt(2*pi)
plot(1:1000, prior2)
df$norm <- l*prior2
df$norm <- df$norm/sum(df$norm)
ggplot(df_m, aes(x=hyp, y=posterior, color=prior)) + geom_line() + xlab("Number of trains") +
ylab("Probability") +
scale_color_brewer(palette="Dark2")
library(tidyverse)
ggplot(df_m, aes(x=hyp, y=posterior, color=prior)) + geom_line() + xlab("Number of trains") +
ylab("Probability") +
scale_color_brewer(palette="Dark2")
df_m <- df %>% gather(prior, posterior, unif, power)
ggplot(df_m, aes(x=hyp, y=posterior, color=prior)) + geom_line() + xlab("Number of trains") +
ylab("Probability") +
scale_color_brewer(palette="Dark2")
df_m <- df %>% gather(prior, posterior, unif, power, norm)
ggplot(df_m, aes(x=hyp, y=posterior, color=prior)) + geom_line() + xlab("Number of trains") +
ylab("Probability") +
scale_color_brewer(palette="Dark2")
prior2 <- exp(-(1:1000/10)^2)/sqrt(2*pi)
df$norm <- l*prior2
df$norm <- df$norm/sum(df$norm)
df_m <- df %>% gather(prior, posterior, unif, power, norm)
ggplot(df_m, aes(x=hyp, y=posterior, color=prior)) + geom_line() + xlab("Number of trains") +
ylab("Probability") +
scale_color_brewer(palette="Dark2")
prior2 <- exp(-(1:1000/100)^2)/sqrt(2*pi)
df$norm <- l*prior2
df$norm <- df$norm/sum(df$norm)
df_m <- df %>% gather(prior, posterior, unif, power, norm)
ggplot(df_m, aes(x=hyp, y=posterior, color=prior)) + geom_line() + xlab("Number of trains") +
ylab("Probability") +
scale_color_brewer(palette="Dark2")
?dbeta
x <- seq(0, 1, 0.01)
df <- data.frame(x, dbeta(x, 0.5, 0.4))
ggplot(df, aes(x=x, y=d)) + geom_line()
x <- seq(0, 1, 0.01)
df <- data.frame(x, dbeta(x, 0.5, 0.4))
df <- data.frame(x, d=dbeta(x, 0.5, 0.4))
ggplot(df, aes(x=x, y=d)) + geom_line()
x <- seq(0, 1, 0.01)
df <- data.frame(x, d=dbeta(x, 2, 0.4))
ggplot(df, aes(x=x, y=d)) + geom_line()
df <- data.frame(x, d=dbeta(x, 0.5, 2))
ggplot(df, aes(x=x, y=d)) + geom_line()
library("LearnBayes")
install.packages("LearnBayes")
library("LearnBayes")
help(package="LearnBayes")
?betabinexch
beta.selec
beta.select
?beta.select
?binomial.beta.mix
?pbetap
pbetap
betabin_posterior <- function(x, n, a, b) {
p <- seq(0, 1, 0.01)
post <- dbeta(a+x, b+n-x)
}
betabin_posterior <- function(x, n, a, b) {
p <- seq(0, 1, 0.01)
post <- dbeta(a+x, b+n-x)
df <- data.frame(p, post)
return(df)
}
df <- betabin_posterior(650, 1000, 0.5, 0.4)
betabin_posterior <- function(x, n, a, b) {
p <- seq(0, 1, 0.01)
post <- dbeta(p, a+x, b+n-x)
df <- data.frame(p, post)
return(df)
}
df <- betabin_posterior(650, 1000, 0.5, 0.4)
ggplot(df, aes(x=p, y=post)) + geom_line()
(0.5+650)/(0.5+65+0.4+1000-650)
(0.5+650)/(0.5+650+0.4+1000-650)
a <- 0.5+650
b <- 0.4+1000-650
a/(a+b)
a*b/((a+b)^2*(a+b+1)
betabin_posterior <- function(x, n, a, b) {
a*b/((a+b)^2*(a+b+1))
library(tidyverse)
melb_auctions <- read_csv("melb_auctions.csv")
clayton <- melb_auctions %>% filter(suburb == "Clayton")
ggplot(clayton, aes(x=nbeds, y=price)) + geom_point() + facet_wrap(~property_type)
ggplot(clayton, aes(x=nbeds, y=price)) + geom_jitter(width=0.1, height=0) + facet_wrap(~property_type)
table(clayton$year)
lm(price~nbeds, data=filter(clayton, property_type=="h"))
summary(lm(price~nbeds, data=filter(clayton, property_type=="h")))
summary(lm(price~nbeds, data=filter(clayton, property_type=="t")))
devtools::install_github("dkahle/ggmap")
devtools::install_github("tidyverse/ggplot2")
?install_github
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
echo = FALSE,
collapse = TRUE,
comment = "#",
fig.height = 3,
fig.width = 3,
fig.align = "center",
cache = FALSE
)
library(knitr)
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggmap)
library(lubridate)
library(broom)
# Read stations data
stations <- read_table("../data/ghcnd-stations.txt",
col_names=c("ID", "lat", "lon", "elev", "state", "name",
"v1", "v2", "v3"), skip=353, n_max=17081)
oz <- map_data("world", xlim=range(stations$lon),
ylim=range(stations$lat))
ggplot(oz, aes(x=long, y=lat)) + geom_path(aes(group=group)) +
coord_quickmap() +
geom_point(data=stations, aes(x=lon, y=lat),
colour="red", alpha=0.5)
ped_loc <- read_csv("../data/Pedestrian_Sensor_Locations.csv")
melb <- get_map(location=c(mean(range(ped_loc$Longitude)),
mean(range(ped_loc$Latitude))), zoom=14)
ggmap(melb) + geom_point(data=ped_loc,
aes(x=Longitude, y=Latitude),
colour="#c51b7d", alpha=0.5, size=3)
install_github("hadley/ggplot2@v2.2.0")
devtools::install_github("hadley/ggplot2@v2.2.0")
knitr::opts_chunk$set(
message = FALSE,
warning = FALSE,
error = FALSE,
echo = FALSE,
collapse = TRUE,
comment = "#",
fig.height = 3,
fig.width = 3,
fig.align = "center",
cache = FALSE
)
library(knitr)
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggmap)
library(lubridate)
library(broom)
# Read stations data
stations <- read_table("../data/ghcnd-stations.txt",
col_names=c("ID", "lat", "lon", "elev", "state", "name",
"v1", "v2", "v3"), skip=353, n_max=17081)
oz <- map_data("world", xlim=range(stations$lon),
ylim=range(stations$lat))
ggplot(oz, aes(x=long, y=lat)) + geom_path(aes(group=group)) +
coord_quickmap() +
geom_point(data=stations, aes(x=lon, y=lat),
colour="red", alpha=0.5)
install.packages("tidyverse")
library(ggmap)
us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")
ggmap(map)
df <- data.frame(x=sample(-110:-90, 10), y=sample(35:45, 10))
ggmap(map) + geom_point(df, aes(x=x, y=y))
df
?qmplot
qmplot(lon, lat, data = crime)
head(crime)
qmplot(Longitude, Latitude data=ped_loc)
qmplot(Longitude, Latitude, data=ped_loc)
devtools::install_github("tidyverse/ggplot2")
qmplot(lon, lat, data = crime)
library(ggmap)
qmplot(lon, lat, data = crime)
install.packages("tidyverse")
qmplot(lon, lat, data = crime)
devtools::install_github("hadley/ggplot2@v2.2.0")
qmplot(lon, lat, data = crime)
library(ggmap)
qmplot(lon, lat, data = crime)
stations <- read_table("../data/ghcnd-stations.txt",
col_names=c("ID", "lat", "lon", "elev", "state", "name",
"v1", "v2", "v3"), skip=353, n_max=17081)
library(readr)
stations <- read_table("../data/ghcnd-stations.txt",
col_names=c("ID", "lat", "lon", "elev", "state", "name",
"v1", "v2", "v3"), skip=353, n_max=17081)
oz <- map_data("world", xlim=range(stations$lon),
ylim=range(stations$lat))
ggplot(oz, aes(x=long, y=lat)) + geom_path(aes(group=group)) +
coord_quickmap() +
geom_point(data=stations, aes(x=lon, y=lat),
colour="red", alpha=0.5)
ped_loc <- read_csv("../data/Pedestrian_Sensor_Locations.csv")
qmplot(Longitude, Latitude, data=ped_loc, colour=I("red"), size=I(3))
melb_stns <- stations %>% filter(lon > min(ped_loc$Longitude),
lon < max(ped_loc$Longitude),
lat > min(ped_loc$Latitude),
lat < max(ped_loc$Latitude))
library(tidyverse)
melb_stns <- stations %>% filter(lon > min(ped_loc$Longitude),
lon < max(ped_loc$Longitude),
lat > min(ped_loc$Latitude),
lat < max(ped_loc$Latitude))
qmplot(Longitude, Latitude, data=melb_stns, colour=I("red"), size=I(3))
qmplot(lon, lat, data=melb_stns, colour=I("red"), size=I(3))
head(melb_stns)
